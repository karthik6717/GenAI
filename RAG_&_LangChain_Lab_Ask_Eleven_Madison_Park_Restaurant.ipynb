{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSRALUfSt8R5Dzedv++Nra",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthik6717/GenAI/blob/master/RAG_%26_LangChain_Lab_Ask_Eleven_Madison_Park_Restaurant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2-uz039yLXz"
      },
      "outputs": [],
      "source": [
        "# We start by installing the libraries we need and setting up our OpenAI API key\n",
        "# This cell installs the necessary libraries. Please run it once\n",
        "\n",
        "# VERY IMPORTANT: Microsoft Visual C++ 14.0 or greater is required before running this cell\n",
        "# https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
        "\n",
        "# The '-q' flag makes the installation less verbose\n",
        "print(\"Installing necessary libraries...\")\n",
        "!pip install -q langchain langchain-openai openai chromadb gradio python-dotenv tiktoken langchain-community\n",
        "print(\"Libraries installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's install and import OpenAI Package\n",
        "!pip install --upgrade openai\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# Let's import os, which stands for \"Operating System\"\n",
        "import os\n",
        "\n",
        "# This will be used to load the API key from the .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Get the OpenAI API keys from environment variables\n",
        "#openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Get the OpenAI API key from Colab secrets\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Let's configure the OpenAI Client using our key\n",
        "openai_client = OpenAI(api_key=openai_api_key)\n",
        "print(\"OpenAI client successfully configured.\")\n",
        "\n",
        "# Let's view the first few characters in the key\n",
        "print(openai_api_key[:15])"
      ],
      "metadata": {
        "id": "MIEyasObzTu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's import Langchain components\n",
        "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
        "from langchain_community.vectorstores import Chroma\n",
        "# Install and import the dedicated text splitters package\n",
        "!pip install -q langchain-text-splitters\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.chains import RetrievalQAWithSourcesChain"
      ],
      "metadata": {
        "id": "f25xERNY0I0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your data file\n",
        "# Ensure 'eleven_madison_park_data.txt' is in the same folder as this notebook\n",
        "DATA_FILE_PATH = \"eleven_madison_park_data.txt\"\n",
        "print(f\"Data file path set to: {DATA_FILE_PATH}\")"
      ],
      "metadata": {
        "id": "QDAD907t3gzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load Eleven Madison Park Restaurant data, which has been scraped from their website\n",
        "# The data is saved in \"eleven_madison_park_data.txt\", Langchain's TextLoader makes this easy to read\n",
        "print(f\"Attempting to load data from: {DATA_FILE_PATH}\")\n",
        "\n",
        "# Initialize the TextLoader with the file path and specify UTF-8 encoding\n",
        "# Encoding helps handle various characters correctly\n",
        "loader = TextLoader(DATA_FILE_PATH, encoding = \"utf-8\")\n",
        "\n",
        "# Load the document(s) using TextLoader from LangChain, which loads the entire file as one Document object\n",
        "raw_documents = loader.load()\n",
        "print(f\"Successfully loaded {len(raw_documents)} document(s).\")"
      ],
      "metadata": {
        "id": "rmu7wkql3lS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's display a few characters of the loaded content to perform a sanity check!\n",
        "print(raw_documents[0].page_content[:500] + \"...\")"
      ],
      "metadata": {
        "id": "tIcRtc0Y3psQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}