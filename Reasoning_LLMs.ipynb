{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1qiNbQaMO7sSAGYYKFwk5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthik6717/GenAI/blob/master/Reasoning_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB8TDYb4ojKh"
      },
      "outputs": [],
      "source": [
        "print(\"Installing necessary libraries...\")\n",
        "\n",
        "# Transformers: Lets you easily use powerful pre-trained AI models for tasks like text generation, translation, or classification.\n",
        "# Accelerate: Helps you run and train models efficiently across CPUs, GPUs.\n",
        "# BitsAndBytes: Reduces the size of large models using quantization so they can fit and run on limited hardware like free GPUs.\n",
        "# Torch (PyTorch): A deep learning library used to build, train, and run neural networks using tensors and GPU acceleration.\n",
        "\n",
        "# Added 'datasets' to the list\n",
        "!pip install -q transformers accelerate bitsandbytes torch datasets gradio\n",
        "\n",
        "print(\"Libraries installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face Login\n",
        "\n",
        "import os\n",
        "from huggingface_hub import login, notebook_login\n",
        "\n",
        "print(\"Attempting Hugging Face login...\")\n",
        "\n",
        "notebook_login()\n",
        "print(\"Login successful (or token already present)!\")"
      ],
      "metadata": {
        "id": "1_fIo18ao7vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from datasets import load_dataset  # Import the dataset loading function\n",
        "import gradio as gr\n",
        "from IPython.display import display, Markdown\n",
        "import random  # To pick random news items\n",
        "\n",
        "# Check for GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "    torch.set_default_device(\"cuda\")\n",
        "    print(\"PyTorch default device set to CUDA (GPU).\")\n",
        "else:\n",
        "    print(\"WARNING: No GPU detected. Performance will be very slow.\")\n",
        "    print(\"Go to Runtime > Change runtime type and select GPU.\")"
      ],
      "metadata": {
        "id": "no847YacpCoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for markdown display\n",
        "def print_markdown(text):\n",
        "    \"\"\"Displays text as Markdown.\"\"\"\n",
        "    display(Markdown(text))"
      ],
      "metadata": {
        "id": "YLtz1HICpXVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_id = \"PaulAdversarial/all_news_finance_sm_1h2023\"\n",
        "\n",
        "print(f\"Loading dataset: {dataset_id}...\")\n",
        "\n",
        "# Load the dataset (will download if not cached)\n",
        "# We might only need the 'train' split, specify split = 'train' if needed\n",
        "# The datatype of news_dataset is datasets.Dataset (from the datasets library by Hugging Face).\n",
        "news_dataset = load_dataset(dataset_id, split = \"train\")\n",
        "print(\"Dataset loaded successfully!\")"
      ],
      "metadata": {
        "id": "MlSA7UwkpYzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's Inspect the dataset\n",
        "news_dataset"
      ],
      "metadata": {
        "id": "Uq58JAROpgO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's display the features (columns and their types)\n",
        "print(\"\\n Dataset Features\")\n",
        "print(news_dataset.features)"
      ],
      "metadata": {
        "id": "erTovtmppkbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's view the datasets as a Pandas DataFrame\n",
        "news_dataset.to_pandas()"
      ],
      "metadata": {
        "id": "bqcrcze3pwb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's prepare the data for the LLM\n",
        "# We'll combine title and description for the input text\n",
        "def combine_news_text(example):\n",
        "\n",
        "    # Handle potential None values gracefully\n",
        "    title = example.get(\"title\", \"\") or \"\"\n",
        "    description = example.get(\"description\", \"\") or \"\"\n",
        "\n",
        "    # Add a separator for clarity\n",
        "    return {\"full_text\": f\"Title: {title}\\nDescription: {description}\"}"
      ],
      "metadata": {
        "id": "M6NTPaftp_BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's apply the function to combine the 'title' and 'description' into 'full_text'\n",
        "# This uses map, which is efficient for datasets\n",
        "\n",
        "news_dataset = news_dataset.map(combine_news_text)\n",
        "\n",
        "print(\"\\n--- Sample Data with 'full_text' ---\")\n",
        "print(news_dataset[0])"
      ],
      "metadata": {
        "id": "D0CNfWTpqDu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's display the full_text of the first sample\n",
        "print(news_dataset[0][\"full_text\"])"
      ],
      "metadata": {
        "id": "zBhXuxfYqFaD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}